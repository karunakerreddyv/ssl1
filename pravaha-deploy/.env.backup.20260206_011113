# =============================================================================
# PRAVAHA PLATFORM - SINGLE SERVER DEPLOYMENT CONFIGURATION
# =============================================================================
#
# This is the SSOT (Single Source of Truth) for all services in Docker deployment.
# All services (backend, ML service, Superset, Celery workers) read from this file.
#
# Quick Start:
#   1. Copy this file: cp .env.example .env
#   2. Run install.sh to auto-generate secrets: ./scripts/install.sh --domain your-domain.com
#   OR manually generate secrets (see commands below)
#   3. Run: docker compose up -d
#
# Secret Generation Commands:
#   JWT_SECRET:           openssl rand -base64 48
#   ENCRYPTION_KEY:       openssl rand -hex 16
#   SUPERSET_SECRET_KEY:  openssl rand -base64 48
#   POSTGRES_PASSWORD:    openssl rand -base64 24
#   MODEL_SIGNING_KEY:    openssl rand -hex 32
#   ML_SERVICE_API_KEY:   openssl rand -base64 32
#   DATA_ENCRYPTION_KEY:  openssl rand -hex 32
#   HMAC_SECRET:          openssl rand -hex 32
#
# Audit Key Generation (for compliance):
#   openssl genrsa -out audit-private.pem 2048
#   openssl rsa -in audit-private.pem -outform PEM -pubout -out audit-public.pem
#
# =============================================================================

# =============================================================================
# SECTION 1: DEPLOYMENT CONFIGURATION
# =============================================================================

# -----------------------------------------------------------------------------
# 1.1 Platform Admin Credentials
# Generated during installation - CHANGE THESE FOR PRODUCTION
# -----------------------------------------------------------------------------
ADMIN_EMAIL=admin@localhost
ADMIN_PASSWORD=hAWJgdUW6VC1WXDbGQNTjF7n
ADMIN_DISPLAY_NAME="Platform Admin"

# -----------------------------------------------------------------------------
# 1.2 Domain & URLs
# Update these for your deployment
# -----------------------------------------------------------------------------
DOMAIN=localhost
FRONTEND_URL=https://localhost
API_BASE_URL=https://localhost/api
ALLOWED_ORIGINS=https://localhost
CORS_ORIGIN=https://localhost

# -----------------------------------------------------------------------------
# 1.3 Container Registry
# Default: Docker Hub (karunakervgrc organization)
# Supported registries:
#   Docker Hub: REGISTRY=karunakervgrc
#   GHCR:       REGISTRY=ghcr.io/talentfino/pravaha
# -----------------------------------------------------------------------------
REGISTRY=ghcr.io/talentfino/pravaha
IMAGE_TAG=latest

# Docker Registry Credentials (set as environment variables before install.sh)
# DOCKER_USERNAME=karunakervgrc
# DOCKER_PASSWORD=<access-token>  # Use Docker Hub Access Token, NOT password

# -----------------------------------------------------------------------------
# 1.4 Branding
# Override these to white-label the platform
# -----------------------------------------------------------------------------
BRAND=pravaha
BRAND_PREFIX=pravaha
BRAND_NAME=Pravaha

# License Management
LICENSE_PUBLIC_KEY_PATH=
LICENSE_SUPPORT_EMAIL=support@pravaha.io
LICENSE_ENFORCEMENT_MODE=disabled

# =============================================================================
# SECTION 2: SHARED INFRASTRUCTURE
# Used by ALL services - values must be consistent
# =============================================================================

# -----------------------------------------------------------------------------
# 2.1 Database Configuration (PostgreSQL)
# Single PostgreSQL instance with multiple databases
# Supports both bundled Docker PostgreSQL and external PostgreSQL servers
# -----------------------------------------------------------------------------

# Database Mode: "bundled" (Docker container) or "external" (separate server)
# Set to "external" to use an external PostgreSQL server (RDS, Azure, self-hosted)
POSTGRES_MODE=bundled

# External PostgreSQL Connection (only used when POSTGRES_MODE=external)
# For bundled mode, these are ignored and 'postgres' container is used
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# PostgreSQL Credentials (used for both bundled and external modes)
POSTGRES_USER=pravaha
POSTGRES_PASSWORD=B0MCOFLn9GCu1OWk6FhbtuYVvoHSbHyD

# Platform database (backend + ML service)
PLATFORM_DB=autoanalytics

# Superset database (in same PostgreSQL instance)
SUPERSET_DB=superset

# PostgreSQL SSL Configuration (for external PostgreSQL with SSL)
# Only applies when POSTGRES_MODE=external
# SSL Modes: disable, allow, prefer, require, verify-ca, verify-full
POSTGRES_SSL_ENABLED=false
POSTGRES_SSL_MODE=prefer

# Full DATABASE_URL (auto-constructed based on POSTGRES_MODE)
# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE
# Note: When POSTGRES_MODE=bundled, host defaults to 'postgres' (container name)
# Note: When POSTGRES_MODE=external, uses POSTGRES_HOST value
DATABASE_URL=postgresql://pravaha:B0MCOFLn9GCu1OWk6FhbtuYVvoHSbHyD@postgres:5432/autoanalytics

# Database Connection Pool (ML Service - SQLAlchemy)
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=40
DB_POOL_TIMEOUT=180
DB_POOL_RECYCLE=3600

# Async Pool (ML Service - Asyncpg)
ASYNCPG_MIN_SIZE=5
ASYNCPG_MAX_SIZE=40
ASYNCPG_COMMAND_TIMEOUT=1800
ASYNCPG_MAX_INACTIVE_LIFETIME=300

# -----------------------------------------------------------------------------
# 2.2 Redis Configuration
# Used for caching, session storage, and Celery task queue
# -----------------------------------------------------------------------------
# Option 1: No password (simpler, for internal networks)
#   Leave REDIS_PASSWORD empty
#
# Option 2: With password (more secure)
#   Set REDIS_PASSWORD and update REDIS_URL
#   REDIS_URL=redis://:your_password@redis:6379

REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_URL=redis://redis:6379
REDIS_MAX_CONNECTIONS=100

# Redis Memory Management (Production Critical)
# Set appropriate maxmemory based on your server RAM
# Recommended: 25-50% of available RAM for single-server deployments
# Format: <number><unit> where unit is kb, mb, or gb
# Set to 0 for no limit (not recommended in production)
REDIS_MAXMEMORY=1gb

# Redis eviction policy when maxmemory is reached
# Recommended: allkeys-lru (evict least recently used keys)
# Options: noeviction, allkeys-lru, volatile-lru, allkeys-random, volatile-random, volatile-ttl
REDIS_MAXMEMORY_POLICY=allkeys-lru

# -----------------------------------------------------------------------------
# 2.3 JWT Authentication (CRITICAL - SHARED SECRET)
# MUST be identical for all services for token validation to work!
# Generate: openssl rand -base64 48
# -----------------------------------------------------------------------------
JWT_SECRET=CHANGE_ME_GENERATE_SECURE_64_CHAR_SECRET
JWT_EXPIRES_IN=7d

# -----------------------------------------------------------------------------
# 2.4 Logging & Monitoring (SHARED)
# Use lowercase: debug, info, warning, error, critical
# -----------------------------------------------------------------------------
LOG_LEVEL=info

# OpenTelemetry Distributed Tracing (optional)
OTEL_ENABLED=false
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAMESPACE=pravaha-platform

# =============================================================================
# SECTION 3: SECURITY SECRETS
# Generate all secrets before production deployment!
# =============================================================================

# -----------------------------------------------------------------------------
# 3.1 Encryption Keys
# -----------------------------------------------------------------------------
# General encryption key (32 hex chars)
# Generate: openssl rand -hex 16
ENCRYPTION_KEY=3d8c24b10495cba3cd346039d2342469

# Credential Encryption Master Key (for encrypting stored credentials)
# Generate: openssl rand -hex 32
CREDENTIAL_MASTER_KEY=279e5adbeb87e695ba46cfc2156aed7f6ff022cf55861cbb108ed3af5b7f9726

# Data Encryption Key (must be 64 hex chars)
# Generate: openssl rand -hex 32
DATA_ENCRYPTION_KEY=08436c08efc73a415e3f856a573d370caec13affe16392d726911184b50659f4

# Exception Encryption Key (must be 64 hex chars)
# Generate: openssl rand -hex 32
EXCEPTION_ENCRYPTION_KEY=401efca07df61172e5efba1cfcb89f78e295442468e2c19a76099a8a5ac9e0be

# CCM Encryption Key (for CCM module data encryption)
# Generate: openssl rand -hex 32
CCM_ENCRYPTION_KEY=3099ce6e362286f9a7d9252347f9ad204e1466145afb55de3a04595a88691d27

# Storage Encryption Key (for CCM storage provider credentials)
# Generate: openssl rand -hex 32
STORAGE_ENCRYPTION_KEY=1a7c7f3e1cae5b54075f10a0dae705694a039475e5e04ef51fb6d7348b07f410

# Evidence HMAC Secret (for evidence file integrity signatures)
# Generate: openssl rand -hex 32
EVIDENCE_HMAC_SECRET=f52c5611eec995c6a474f5f56fdad96530e280a49f8502ebdea76dfd772f1ad8

# ML Credential Encryption Key (Fernet symmetric encryption for ML datasource credentials)
# CRITICAL: Encrypts sensitive fields (passwords, API keys) in ML credentials stored in ml_credentials table
# Generate: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# WARNING: Changing this key will make existing encrypted ML credentials unreadable
ML_CREDENTIAL_ENCRYPTION_KEY=Y0jkuOot_KwVqioWU4fcrzdJN97RHGTGt0DQY6STxPE=

# -----------------------------------------------------------------------------
# 3.2 Session & CSRF Protection
# -----------------------------------------------------------------------------
# Session secret (defaults to JWT_SECRET if not set)
SESSION_SECRET=lav2B2ePIWv2lUIQFaMVO2V3w5ez84mIis42d3Bjn22tgipMTdNG1dYjx4iTYE5j
SESSION_MAX_AGE=604800000

# CSRF Protection Secret
# Generate: openssl rand -base64 32
CSRF_SECRET=8ChJKnH3dwl1HCUjsTWEuew5IlVU2YEJUFLlfIlE
ENABLE_CSRF=true

# -----------------------------------------------------------------------------
# 3.3 Signature Keys
# -----------------------------------------------------------------------------
# Data Lineage Signature Secret
# Generate: openssl rand -hex 32
LINEAGE_SIGNATURE_SECRET=94a5d873baf437326e066a7e83db5f322ed0a79df69a77508ce5489822af8e84

# Audit Signature Secret (for audit log integrity)
# Generate: openssl rand -hex 32
AUDIT_SIGNATURE_SECRET=318d340cf4a1ed82193aa64547148c41885b4ad4bccebbbbd9220cf75f0acae7

# -----------------------------------------------------------------------------
# 3.4 HMAC Request Signing
# -----------------------------------------------------------------------------
HMAC_ENABLED=true
HMAC_SECRET=145ea81f2052e00406890a6924a3ee41980f983ab271e8e9cd14d70cfc06c154
HMAC_WINDOW_MS=300000

# =============================================================================
# SECTION 4: BACKEND SERVICE (Node.js/TypeScript)
# =============================================================================

# -----------------------------------------------------------------------------
# 4.1 Server Configuration
# -----------------------------------------------------------------------------
NODE_ENV=production
PORT=3000
HOST=0.0.0.0
SERVICE_NAME=pravaha-backend

# Security Headers
HELMET_ENABLED=true

# AI workflow generation (set to false when OpenAI API key configured)
AI_MOCK_MODE=true

# -----------------------------------------------------------------------------
# 4.2 Rate Limiting
# -----------------------------------------------------------------------------
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=1000
TRUSTED_IPS=127.0.0.1,::1

# -----------------------------------------------------------------------------
# 4.3 File Upload
# -----------------------------------------------------------------------------
MAX_FILE_SIZE=10485760
UPLOAD_DIR=/app/uploads

# NGINX Max Upload Size (for file uploads via reverse proxy)
# This sets client_max_body_size in NGINX configuration
MAX_UPLOAD_SIZE_MB=500

# -----------------------------------------------------------------------------
# 4.4 Virus Scanning (ClamAV) - OPTIONAL
# -----------------------------------------------------------------------------
# ClamAV is optional. Set CLAMAV_ENABLED=true to enable virus scanning.
# Requires ClamAV daemon running (install: apt install clamav-daemon)
CLAMAV_ENABLED=false
CLAMAV_HOST=localhost
CLAMAV_PORT=3310
CLAMAV_TIMEOUT=30000

# -----------------------------------------------------------------------------
# 4.5 Feature Flags
# -----------------------------------------------------------------------------
ENABLE_ANALYTICS=true
ENABLE_METRICS=true
ENABLE_SWAGGER_DOCS=false

# -----------------------------------------------------------------------------
# 4.6 ML Platform Limits
# -----------------------------------------------------------------------------
ML_MAX_MODEL_UPLOAD_MB=500
ML_MAX_TRAINING_DATA_MB=100
ML_MAX_DATASET_UPLOAD_MB=200
PAGINATION_DEFAULT_PAGE_SIZE=10
PAGINATION_MAX_PAGE_SIZE=100

# =============================================================================
# SECTION 5: ML SERVICE (Python/FastAPI)
# =============================================================================

# -----------------------------------------------------------------------------
# 5.1 Server Configuration
# -----------------------------------------------------------------------------
ML_SERVICE_HOST=0.0.0.0
ML_SERVICE_PORT=8001
ENVIRONMENT=production
DEBUG=false
API_PREFIX=/api/v1

# ML Service URL (for backend to communicate)
ML_SERVICE_URL=http://ml-service:8001

# API Key for backend-to-ML-service authentication
# Generate: openssl rand -base64 32
ML_SERVICE_API_KEY=2k8Y68QGragpwKW9SLIcF2rrBVzhjYFY8bq7MOohpE
API_KEY_ENABLED=true
API_KEY=2k8Y68QGragpwKW9SLIcF2rrBVzhjYFY8bq7MOohpE

# ML Service HMAC Authentication (Enterprise Security)
# HMAC signing is ENABLED by default for secure inter-service communication
# Generate secret: openssl rand -hex 32
ML_SERVICE_HMAC_ENABLED=true
ML_SERVICE_HMAC_SECRET=145ea81f2052e00406890a6924a3ee41980f983ab271e8e9cd14d70cfc06c154

# Log level for ML service
ML_LOG_LEVEL=info

# Circuit breaker (disable for internal Docker network)
ML_CIRCUIT_BREAKER_ENABLED=false

# -----------------------------------------------------------------------------
# 5.2 Uvicorn Workers
# -----------------------------------------------------------------------------
ML_UVICORN_WORKERS=4
UVICORN_WORKERS=4
UVICORN_TIMEOUT_KEEP_ALIVE=5
UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN=30
UVICORN_LIMIT_MAX_REQUESTS=10000
UVICORN_ACCESS_LOG=true

# CORS (ML Service)
CORS_ORIGINS=https://localhost

# -----------------------------------------------------------------------------
# 5.3 Model Storage
# -----------------------------------------------------------------------------
MODEL_STORAGE_PATH=/app/models
ML_STORAGE_PATH=/data/ml-storage
MODEL_CACHE_SIZE=10

# SSOT Algorithm Configuration Path (Optional - rarely needed)
# Algorithm JSON files are automatically located in Docker images at /shared/algorithms/core
# Only override for custom deployments where algorithms are stored elsewhere
# SSOT_ALGORITHMS_PATH=/custom/path/to/algorithms/core
MAX_MODELS=50

# Model signing key for integrity verification
# Generate: openssl rand -hex 32
MODEL_SIGNING_KEY=c249cf4e881d686ad565d3fd624e4fd3317389379f6cb3a01688ad8687261bf1

# Service-to-service authentication key (Express backend â†’ ML Service)
# Enables rate limit bypass for internal calls in multi-server deployments
INTERNAL_SERVICE_KEY=rV7ZdKHSVkMDPtnzTfL11J4yBAGzDyJjFY6fhpXWg

# -----------------------------------------------------------------------------
# 5.4 Rate Limiting (ML Service)
# -----------------------------------------------------------------------------
RATE_LIMIT_ENABLED=true
ML_RATE_LIMIT_ENABLED=true
MAX_PREDICTIONS_PER_DAY=10000
MAX_TRAINING_JOBS_PER_MONTH=100
MAX_BATCH_SIZE=1000

# -----------------------------------------------------------------------------
# 5.5 Celery Task Queue
# Redis DB Allocation:
#   DB 0: Backend (caching, sessions)
#   DB 1: Superset (caching)
#   DB 2: ML Service (caching)
#   DB 3: Celery (task queue broker and results)
# -----------------------------------------------------------------------------
CELERY_BROKER_URL=redis://redis:6379/3
CELERY_RESULT_BACKEND=redis://redis:6379/3
CELERY_TASK_TIME_LIMIT=7200
CELERY_TASK_SOFT_TIME_LIMIT=6900

# Celery Worker Concurrency
CELERY_TRAINING_CONCURRENCY=4
CELERY_PREDICTION_CONCURRENCY=4
CELERY_MONITORING_CONCURRENCY=2

# -----------------------------------------------------------------------------
# 5.6 Training Timeouts
# -----------------------------------------------------------------------------
TRAINING_TIMEOUT_SECONDS=14400
TRAINING_SOFT_TIMEOUT_SECONDS=14100
TUNING_TIMEOUT_SECONDS=14400
BATCH_PREDICTION_TIMEOUT_SECONDS=3600

# -----------------------------------------------------------------------------
# 5.7 Algorithm Configuration
# -----------------------------------------------------------------------------
ENABLE_CONFIGURABLE_ALGORITHMS=false
ENABLE_EXTENDED_ALGORITHMS=true
ENABLE_ADVANCED_ALGORITHMS=true
LAZY_LOAD_HEAVY_DEPS=true
GPU_REQUIRED_FOR_ADVANCED=true
GPU_MINIMUM_MEMORY_GB=4.0

# =============================================================================
# SECTION 6: SUPERSET CONFIGURATION
# =============================================================================

# -----------------------------------------------------------------------------
# 6.1 Superset Admin
# -----------------------------------------------------------------------------
SUPERSET_SECRET_KEY=CHANGE_ME_GENERATE_SECURE_64_CHAR_SECRET
SUPERSET_ADMIN_USERNAME=admin
SUPERSET_ADMIN_EMAIL=admin@example.com
SUPERSET_ADMIN_PASSWORD=TStMazNpxByDBYS1v2yk8Q

# -----------------------------------------------------------------------------
# 6.2 Superset Performance
# -----------------------------------------------------------------------------
SUPERSET_WORKERS=4
SUPERSET_WEBSERVER_TIMEOUT=300
SUPERSET_ENABLE_SYNC=true

# Superset URLs (internal Docker network)
SUPERSET_URL=http://superset:8088
SUPERSET_API_URL=http://superset:8088

# Platform Database for ML Analytics Dashboards
# Note: PLATFORM_DATABASE_URL is constructed by docker-compose from:
#   POSTGRES_USER, POSTGRES_PASSWORD, PLATFORM_DB
# This allows Superset to access ml_predictions, ml_models tables for analytics
# No manual configuration required - docker-compose handles the substitution

# =============================================================================
# SECTION 7: NODE BACKEND -> ML SERVICE COMMUNICATION
# =============================================================================

# Backend timeout when calling ML service
NODE_BACKEND_URL=http://backend:3000
NODE_BACKEND_TIMEOUT_SECONDS=900

# =============================================================================
# SECTION 8: JUPYTER NOTEBOOK SERVER (Optional)
# =============================================================================
# Run with: docker compose -f docker-compose.jupyter.yml up -d

# Jupyter Docker image (pin version for reproducibility)
JUPYTER_IMAGE=jupyter/scipy-notebook:2024-01-15

JUPYTER_SERVER_URL=http://jupyter:8888
JUPYTER_TOKEN=WwLJgF4bGrMpdeBFS5WZFIwvGMdi5wWT0mXVq1Stc
JUPYTER_TIMEOUT_SECONDS=3600
JUPYTER_KERNEL_NAME=python3
JUPYTER_WS_TIMEOUT_SECONDS=300
JUPYTER_MAX_KERNELS_PER_TENANT=10
JUPYTER_KERNEL_IDLE_TIMEOUT_MINUTES=30

# Deployment mode: "single" (shared server) or "jupyterhub" (enterprise)
JUPYTER_DEPLOYMENT_MODE=single

# Notebook storage
NOTEBOOK_STORAGE_BACKEND=local
NOTEBOOK_STORAGE_PATH=/data/notebooks
MAX_NOTEBOOK_SIZE_MB=50
NOTEBOOK_EXECUTION_TIMEOUT_SECONDS=7200

# =============================================================================
# SECTION 9: ENTERPRISE AUTHENTICATION (Optional)
# =============================================================================

# -----------------------------------------------------------------------------
# 9.1 LDAP/Active Directory
# -----------------------------------------------------------------------------
LDAP_ENABLED=false
LDAP_URL=ldap://ldap.example.com:389
LDAP_BIND_DN=cn=admin,dc=example,dc=com
LDAP_BIND_PASSWORD=
LDAP_SEARCH_BASE=ou=users,dc=example,dc=com
LDAP_SEARCH_FILTER=(uid={{username}})
LDAP_USERNAME_ATTRIBUTE=uid
LDAP_EMAIL_ATTRIBUTE=mail
LDAP_DISPLAY_NAME_ATTRIBUTE=displayName
LDAP_GROUP_SEARCH_BASE=ou=groups,dc=example,dc=com
LDAP_GROUP_SEARCH_FILTER=(member={{dn}})
LDAP_DEFAULT_ROLE=user
LDAP_TIMEOUT=5000
LDAP_CONNECT_TIMEOUT=10000

# -----------------------------------------------------------------------------
# 9.2 SAML 2.0 SSO
# -----------------------------------------------------------------------------
SAML_ENABLED=false
SAML_SP_ENTITY_ID=https://localhost/saml/metadata
SAML_SP_ACS_URL=https://localhost/saml/acs
SAML_SP_SLO_URL=https://localhost/saml/slo
SAML_IDP_ENTITY_ID=
SAML_IDP_SSO_URL=
SAML_IDP_SLO_URL=
SAML_IDP_CERTIFICATE=
SAML_FORCE_AUTHN=false
SAML_ALLOW_UNENCRYPTED=false
SAML_SIGN_REQUESTS=false
SAML_WANT_ASSERTIONS_SIGNED=true
SAML_DEFAULT_ROLE=user

# =============================================================================
# SECTION 10: EMAIL SERVICE (Optional)
# =============================================================================

SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_SECURE=false
SMTP_USER=
SMTP_PASS=
SMTP_FROM_NAME="Pravaha Platform"
SMTP_FROM_ADDRESS=noreply@example.com
ORGANIZATION_NAME="Your Organization Name"

# =============================================================================
# SECTION 11: DATA RETENTION & CLEANUP
# =============================================================================

DATA_RETENTION_ENABLED=true
DATA_RETENTION_INTERVAL_HOURS=24
RETENTION_FAILED_EXECUTIONS_ENABLED=true
RETENTION_FAILED_EXECUTIONS_DAYS=30
RETENTION_SUCCESSFUL_EXECUTIONS_ENABLED=true
RETENTION_SUCCESSFUL_EXECUTIONS_DAYS=90
RETENTION_LOGS_ENABLED=true
RETENTION_LOGS_DAYS=60

# Session Cleanup
SESSION_RETENTION_DAYS=30
SESSION_CLEANUP_CRON="0 2 * * *"

# =============================================================================
# SECTION 12: WORKER SCALING (Optional - Advanced)
# =============================================================================

SCALING_MIN_WORKERS=2
SCALING_MAX_WORKERS=20
SCALING_TARGET_QUEUE_DEPTH=50
SCALING_UP_THRESHOLD=0.8
SCALING_DOWN_THRESHOLD=0.3
SCALING_UP_COOLDOWN=60000
SCALING_DOWN_COOLDOWN=300000
SCALING_HEALTH_CHECK_INTERVAL=30000
SCALING_WORKER_TIMEOUT=300000
SCALING_MAX_ERROR_RATE=10
SCALING_LOAD_BALANCING_STRATEGY=adaptive

# =============================================================================
# SECTION 13: NOTIFICATIONS (Optional)
# =============================================================================

SLACK_WEBHOOK_URL=
TEAMS_WEBHOOK_URL=
PAGERDUTY_ROUTING_KEY=

# =============================================================================
# SECTION 14: ENTERPRISE MONITORING & OBSERVABILITY (Optional)
# Comprehensive monitoring with Prometheus, Grafana, and Alertmanager
# =============================================================================
#
# LOGGING STACK (Loki + Promtail + Grafana):
#   docker compose -f docker-compose.yml -f docker-compose.logging.yml up -d
#
# METRICS STACK (Prometheus + Grafana + Alertmanager):
#   docker compose -f docker-compose.yml -f docker-compose.metrics.yml up -d
#
# FULL OBSERVABILITY (Both stacks):
#   docker compose -f docker-compose.yml -f docker-compose.logging.yml -f docker-compose.metrics.yml up -d
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# 14.1 Grafana Configuration (Shared by logging and metrics stacks)
# Generate password: openssl rand -base64 24 | tr -d '\n/+='
# -----------------------------------------------------------------------------
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=dez8BYiKxRxKrZa9QOPD6w
GRAFANA_SECRET_KEY=CHANGE_ME_32_CHAR_SECRET_KEY

# Grafana ports (logging stack uses 3001, metrics stack uses 3002)
GRAFANA_LOGS_PORT=3001
GRAFANA_METRICS_PORT=3002

# -----------------------------------------------------------------------------
# 14.2 Prometheus Configuration
# Metrics collection and storage
# -----------------------------------------------------------------------------
PROMETHEUS_PORT=9090
PROMETHEUS_RETENTION=15d
PROMETHEUS_RETENTION_SIZE=10GB

# -----------------------------------------------------------------------------
# 14.3 Alertmanager Configuration
# Alert routing and notification management
# -----------------------------------------------------------------------------
ALERTMANAGER_PORT=9093
ALERTMANAGER_EXTERNAL_URL=http://localhost:9093

# Alert notification emails (configure based on your team structure)
ALERT_EMAIL=ops@pravaha.io
CRITICAL_ALERT_EMAIL=oncall@pravaha.io
DBA_EMAIL=dba@pravaha.io
ML_TEAM_EMAIL=ml-team@pravaha.io
INFRA_EMAIL=infra@pravaha.io

# Slack channels for alerts (optional, configure SLACK_WEBHOOK_URL in Section 13)
SLACK_CRITICAL_CHANNEL=#alerts-critical
SLACK_WARNING_CHANNEL=#alerts
SLACK_DBA_CHANNEL=#alerts-database
SLACK_ML_CHANNEL=#alerts-ml
SLACK_INFRA_CHANNEL=#alerts-infra

# =============================================================================
# SECTION 15: MULTI-TENANCY
# =============================================================================

DEFAULT_TENANT_ID=default

# =============================================================================
# SECTION 16: ELK STACK LOGGING (Optional)
# Enterprise-grade log aggregation with Elasticsearch, Logstash, Kibana
# Usage: docker compose -f docker-compose.yml -f docker-compose.elk.yml up -d
# Access: https://your-domain.com/elk/
# =============================================================================

# -----------------------------------------------------------------------------
# 16.1 Elasticsearch
# Generate password: openssl rand -base64 24 | tr -d '\n/+='
# -----------------------------------------------------------------------------
ELASTICSEARCH_USERNAME=elastic
ELASTIC_PASSWORD=ZUAPproQxOHddkFvMedh66L16IjfDHjm
ELASTIC_SECURITY_ENABLED=true
ELASTIC_HEAP_SIZE=2g
ELASTIC_MEMORY_LIMIT=4G

# -----------------------------------------------------------------------------
# 16.2 Logstash
# -----------------------------------------------------------------------------
LOGSTASH_HEAP_SIZE=1g
LOGSTASH_MEMORY_LIMIT=2G

# -----------------------------------------------------------------------------
# 16.3 Kibana
# Generate encryption keys: openssl rand -base64 32 | tr -d '\n/+='
# Note: All three keys should be at least 32 characters
# -----------------------------------------------------------------------------
KIBANA_SYSTEM_PASSWORD=rP9JgijaxgJV4XOWgSGPowg3Vw50usX
KIBANA_ENCRYPTION_KEY=yruY4JkQw3RU5pOV9d2OYdqbh3Ujo20FQgXZtdYF8
KIBANA_REPORTING_KEY=07NFyzPay2dbRBe0w73WeDH5INcoznnpt7lYdfDw
KIBANA_SECURITY_KEY=I75YjTDVKra0vFRLPUD3u1TwqXuUnJsSmgLGLx0sgfE

# =============================================================================
# SECTION 17: SUPER ADMIN (Platform Administration)
# =============================================================================
# Super Admin has elevated privileges for platform-wide administration
# Generate: openssl rand -base64 48 | tr -d '\n/+='
# -----------------------------------------------------------------------------
SUPER_ADMIN_EMAIL=superadmin@platform.local
SUPER_ADMIN_DEFAULT_PASSWORD=fM0kOOXxz2VXD7X3CTQZZg0
SUPER_ADMIN_JWT_SECRET=BgxbsGNcZD3HZBPL6jRuucplLmDp6YEfmmkPxAHQON8ix9VG3T0d1hOpOmVvXl9q
SUPER_ADMIN_TOKEN_TTL=1h
