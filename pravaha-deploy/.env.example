# =============================================================================
# PRAVAHA PLATFORM - SINGLE SERVER DEPLOYMENT CONFIGURATION
# =============================================================================
#
# This is the SSOT (Single Source of Truth) for all services in Docker deployment.
# All services (backend, ML service, Superset, Celery workers) read from this file.
#
# Quick Start:
#   1. Copy this file: cp .env.example .env
#   2. Run install.sh to auto-generate secrets: ./scripts/install.sh --domain your-domain.com
#   OR manually generate secrets (see commands below)
#   3. Run: docker compose up -d
#
# Secret Generation Commands:
#   JWT_SECRET:             openssl rand -base64 48 | tr -d '\n/+='
#   ENCRYPTION_KEY:         openssl rand -hex 16
#   SUPERSET_SECRET_KEY:    openssl rand -base64 48 | tr -d '\n/+='
#   POSTGRES_PASSWORD:      openssl rand -base64 24 | tr -d '\n/+='
#   MODEL_SIGNING_KEY:      openssl rand -hex 32
#   ML_SERVICE_API_KEY:     openssl rand -base64 32 | tr -d '\n/+='
#   DATA_ENCRYPTION_KEY:    openssl rand -hex 32
#   HMAC_SECRET:            openssl rand -hex 32
#   INTERNAL_SERVICE_KEY:   openssl rand -base64 32 | tr -d '\n/+='
#   GRAFANA_SECRET_KEY:     openssl rand -base64 32 | tr -d '\n/+='
#   JUPYTER_TOKEN:          openssl rand -hex 32
#   FERNET_KEY:             python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
#
# Audit Key Generation (for compliance):
#   openssl genrsa -out audit-private.pem 2048
#   openssl rsa -in audit-private.pem -outform PEM -pubout -out audit-public.pem
#
# =============================================================================

# =============================================================================
# SECTION 1: DEPLOYMENT CONFIGURATION
# =============================================================================

# -----------------------------------------------------------------------------
# 1.1 Platform Admin Credentials
# Generated during installation - CHANGE THESE FOR PRODUCTION
# Generate password: openssl rand -base64 16 | tr -d '\n/+='
# -----------------------------------------------------------------------------
ADMIN_EMAIL=admin@example.com
ADMIN_PASSWORD=CHANGE_ME_ADMIN_PASSWORD
ADMIN_DISPLAY_NAME="Platform Admin"

# -----------------------------------------------------------------------------
# 1.2 Domain & URLs
# Update these for your deployment
# -----------------------------------------------------------------------------
DOMAIN=your-domain.example.com
FRONTEND_URL=https://your-domain.example.com
API_BASE_URL=https://your-domain.example.com/api
ALLOWED_ORIGINS=https://your-domain.example.com
CORS_ORIGIN=https://your-domain.example.com

# -----------------------------------------------------------------------------
# 1.3 Container Registry
# Default: GHCR (ghcr.io/talentfino/pravaha)
# Supported registries:
#   GHCR (default):       REGISTRY=ghcr.io/talentfino/pravaha, IMAGE_PREFIX=
#   Docker Hub:           REGISTRY=karunakervgrc, IMAGE_PREFIX=pravaha-
# -----------------------------------------------------------------------------
REGISTRY=ghcr.io/talentfino/pravaha
IMAGE_TAG=latest
IMAGE_PREFIX=

# Docker Registry Credentials (set as environment variables before install.sh)
# For GHCR: echo "ghp_xxx" | docker login ghcr.io -u USERNAME --password-stdin
# For Docker Hub: docker login -u karunakervgrc

# -----------------------------------------------------------------------------
# 1.4 Branding & White-Label (Enterprise)
# Override these to white-label the platform for your organization
# See branding/README.md for complete white-label guide
# -----------------------------------------------------------------------------
BRAND=cura
BRAND_NAME=Cura

# Runtime Brand Override (Optional - for Kubernetes/multi-server deployments)
# JSON string that overrides filesystem brand.json at container start.
# Takes highest priority over BRAND and filesystem brand.json.
# Example: BRAND_CONFIG='{"name":"ACME","companyName":"ACME Corp",...}'
# Leave empty to use filesystem-based branding (recommended for most deployments)
BRAND_CONFIG=

# License Management (Enterprise)
LICENSE_PUBLIC_KEY_PATH=
LICENSE_SUPPORT_EMAIL=
LICENSE_ENFORCEMENT_MODE=disabled

# =============================================================================
# SECTION 2: SHARED INFRASTRUCTURE
# Used by ALL services - values must be consistent
# =============================================================================

# -----------------------------------------------------------------------------
# 2.1 Database Configuration (PostgreSQL)
# Single PostgreSQL instance with multiple databases
# Supports both bundled Docker PostgreSQL and external PostgreSQL servers
# -----------------------------------------------------------------------------

# Database Mode: "bundled" (Docker container) or "external" (separate server)
# Set to "external" to use an external PostgreSQL server (RDS, Azure, self-hosted)
POSTGRES_MODE=bundled

# External PostgreSQL Connection (only used when POSTGRES_MODE=external)
# For bundled mode, these are ignored and 'postgres' container is used
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# PostgreSQL Credentials (used for both bundled and external modes)
POSTGRES_USER=pravaha
POSTGRES_PASSWORD=CHANGE_ME_SECURE_PASSWORD

# Platform database (backend + ML service)
PLATFORM_DB=autoanalytics

# Superset database (in same PostgreSQL instance)
SUPERSET_DB=superset

# PostgreSQL SSL Configuration (for external PostgreSQL with SSL)
# Only applies when POSTGRES_MODE=external
# SSL Modes: disable, allow, prefer, require, verify-ca, verify-full
# IMPORTANT: Set to any non-empty value (e.g., "true") to enable SSL.
# Leave empty to disable SSL. Do NOT use "false" (non-empty = enabled).
POSTGRES_SSL_ENABLED=
POSTGRES_SSL_MODE=prefer

# Full DATABASE_URL (auto-constructed by docker-compose from variables above)
# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE
# Note: docker-compose.yml dynamically constructs DATABASE_URL for each service.
# This value is only used outside Docker Compose. Update if you changed the above values.
DATABASE_URL=postgresql://pravaha:CHANGE_ME_SECURE_PASSWORD@postgres:5432/autoanalytics

# Database Connection Pool (ML Service - SQLAlchemy)
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=40
DB_POOL_TIMEOUT=180
DB_POOL_RECYCLE=3600

# Async Pool (ML Service - Asyncpg)
ASYNCPG_MIN_SIZE=5
ASYNCPG_MAX_SIZE=40
ASYNCPG_COMMAND_TIMEOUT=1800
ASYNCPG_MAX_INACTIVE_LIFETIME=300

# -----------------------------------------------------------------------------
# 2.2 Redis Configuration
# Used for caching, session storage, and Celery task queue
# -----------------------------------------------------------------------------
# Option 1: No password (simpler, for internal networks)
#   Leave REDIS_PASSWORD empty
#
# Option 2: With password (more secure)
#   Set REDIS_PASSWORD and update REDIS_URL
#   REDIS_URL=redis://:your_password@redis:6379

REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_URL=redis://redis:6379
REDIS_MAX_CONNECTIONS=100

# Redis Memory Management (Production Critical)
# Set appropriate maxmemory based on your server RAM
# Recommended: 25-50% of available RAM for single-server deployments
# Format: <number><unit> where unit is kb, mb, or gb
# Set to 0 for no limit (not recommended in production)
REDIS_MAXMEMORY=1gb

# Redis eviction policy when maxmemory is reached
# Recommended: allkeys-lru (evict least recently used keys)
# Options: noeviction, allkeys-lru, volatile-lru, allkeys-random, volatile-random, volatile-ttl
REDIS_MAXMEMORY_POLICY=allkeys-lru

# -----------------------------------------------------------------------------
# 2.3 JWT Authentication (CRITICAL - SHARED SECRET)
# MUST be identical for all services for token validation to work!
# Generate: openssl rand -base64 48 | tr -d '\n/+='
# -----------------------------------------------------------------------------
JWT_SECRET=CHANGE_ME_GENERATE_SECURE_64_CHAR_SECRET
JWT_EXPIRES_IN=7d

# -----------------------------------------------------------------------------
# 2.4 Logging & Monitoring (SHARED)
# Use lowercase: debug, info, warning, error, critical
# -----------------------------------------------------------------------------
LOG_LEVEL=info

# OpenTelemetry Distributed Tracing (optional)
OTEL_ENABLED=false
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAMESPACE=pravaha-platform

# =============================================================================
# SECTION 3: SECURITY SECRETS
# Generate all secrets before production deployment!
# =============================================================================

# -----------------------------------------------------------------------------
# 3.1 Encryption Keys
# -----------------------------------------------------------------------------
# General encryption key (32 hex chars)
# Generate: openssl rand -hex 16
ENCRYPTION_KEY=CHANGE_ME_32_CHAR_HEX

# Credential Encryption Master Key (for encrypting stored credentials)
# Generate: openssl rand -hex 32
CREDENTIAL_MASTER_KEY=CHANGE_ME_GENERATE_64_CHAR_HEX

# Data Encryption Key (must be 64 hex chars)
# Generate: openssl rand -hex 32
DATA_ENCRYPTION_KEY=CHANGE_ME_GENERATE_64_CHAR_HEX_DATA

# Exception Encryption Key (must be 64 hex chars)
# Generate: openssl rand -hex 32
EXCEPTION_ENCRYPTION_KEY=CHANGE_ME_GENERATE_64_CHAR_HEX_EXCEPTION

# CCM Encryption Key (for CCM module data encryption)
# Generate: openssl rand -hex 32
CCM_ENCRYPTION_KEY=CHANGE_ME_GENERATE_64_CHAR_HEX_CCM

# Storage Encryption Key (for CCM storage provider credentials)
# Generate: openssl rand -hex 32
STORAGE_ENCRYPTION_KEY=CHANGE_ME_GENERATE_64_CHAR_HEX_STORAGE

# Evidence HMAC Secret (for evidence file integrity signatures)
# Generate: openssl rand -hex 32
EVIDENCE_HMAC_SECRET=CHANGE_ME_GENERATE_64_CHAR_HEX_EVIDENCE

# ML Credential Encryption Key (Fernet symmetric encryption for ML datasource credentials)
# CRITICAL: Encrypts sensitive fields (passwords, API keys) in ML credentials stored in ml_credentials table
# Generate: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# WARNING: Changing this key will make existing encrypted ML credentials unreadable
ML_CREDENTIAL_ENCRYPTION_KEY=CHANGE_ME_GENERATE_FERNET_KEY

# -----------------------------------------------------------------------------
# 3.2 Session & CSRF Protection
# -----------------------------------------------------------------------------
# Session secret (defaults to JWT_SECRET if not set)
SESSION_SECRET=
SESSION_MAX_AGE=604800000

# CSRF Protection Secret
# Generate: openssl rand -base64 32 | tr -d '\n/+='
CSRF_SECRET=CHANGE_ME_GENERATE_SECURE_SECRET
ENABLE_CSRF=true

# -----------------------------------------------------------------------------
# 3.3 Signature Keys
# -----------------------------------------------------------------------------
# Data Lineage Signature Secret
# Generate: openssl rand -hex 32
LINEAGE_SIGNATURE_SECRET=CHANGE_ME_GENERATE_64_CHAR_HEX

# Audit Signature Secret (for audit log integrity)
# Generate: openssl rand -hex 32
AUDIT_SIGNATURE_SECRET=CHANGE_ME_GENERATE_64_CHAR_HEX_AUDIT

# -----------------------------------------------------------------------------
# 3.4 HMAC Request Signing
# -----------------------------------------------------------------------------
HMAC_ENABLED=true
HMAC_SECRET=CHANGE_ME_GENERATE_64_CHAR_HEX_HMAC
HMAC_WINDOW_MS=300000

# =============================================================================
# SECTION 4: BACKEND SERVICE (Node.js/TypeScript)
# =============================================================================

# -----------------------------------------------------------------------------
# 4.1 Server Configuration
# -----------------------------------------------------------------------------
NODE_ENV=production
PORT=3000
HOST=0.0.0.0
SERVICE_NAME=pravaha-backend

# Security Headers
HELMET_ENABLED=true

# AI workflow generation (set to false when OpenAI API key configured)
AI_MOCK_MODE=true

# -----------------------------------------------------------------------------
# 4.2 Rate Limiting
# -----------------------------------------------------------------------------
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=1000
TRUSTED_IPS=127.0.0.1,::1

# Trust proxy hops (number of reverse proxy layers, e.g. nginx=1)
TRUST_PROXY_HOPS=1
# Rate Limiting (enterprise defaults — adjust per deployment needs)
RATE_LIMIT_GENERAL_MAX=2000
RATE_LIMIT_GENERAL_WINDOW_MS=60000

# -----------------------------------------------------------------------------
# 4.3 File Upload
# -----------------------------------------------------------------------------
MAX_FILE_SIZE=10485760
UPLOAD_DIR=/app/uploads

# NGINX Max Upload Size (for file uploads via reverse proxy)
# This sets client_max_body_size in NGINX configuration
MAX_UPLOAD_SIZE_MB=500

# -----------------------------------------------------------------------------
# 4.4 Virus Scanning (ClamAV) - OPTIONAL
# -----------------------------------------------------------------------------
# ClamAV is optional. Set CLAMAV_ENABLED=true to enable virus scanning.
# Requires ClamAV daemon running (install: apt install clamav-daemon)
CLAMAV_ENABLED=false
CLAMAV_HOST=localhost
CLAMAV_PORT=3310
CLAMAV_TIMEOUT=30000

# -----------------------------------------------------------------------------
# 4.5 Feature Flags
# -----------------------------------------------------------------------------
ENABLE_ANALYTICS=true
ENABLE_METRICS=true
ENABLE_SWAGGER_DOCS=false

# -----------------------------------------------------------------------------
# 4.6 ML Platform Limits
# -----------------------------------------------------------------------------
ML_MAX_MODEL_UPLOAD_MB=500
ML_MAX_TRAINING_DATA_MB=100
ML_MAX_DATASET_UPLOAD_MB=200
PAGINATION_DEFAULT_PAGE_SIZE=10
PAGINATION_MAX_PAGE_SIZE=100

# =============================================================================
# SECTION 5: ML SERVICE (Python/FastAPI)
# =============================================================================

# -----------------------------------------------------------------------------
# 5.1 Server Configuration
# -----------------------------------------------------------------------------
ML_SERVICE_HOST=0.0.0.0
ML_SERVICE_PORT=8001
ENVIRONMENT=production
DEBUG=false
API_PREFIX=/api/v1

# ML Service URL (for backend to communicate)
ML_SERVICE_URL=http://ml-service:8001

# API Key for backend-to-ML-service authentication
# Generate: openssl rand -base64 32 | tr -d '\n/+='
ML_SERVICE_API_KEY=CHANGE_ME_GENERATE_SECURE_API_KEY
API_KEY_ENABLED=true
# Generate: openssl rand -base64 32 | tr -d '\n/+=' (should match ML_SERVICE_API_KEY above)
API_KEY=CHANGE_ME_GENERATE_SECURE_API_KEY

# ML Service HMAC Authentication (Enterprise Security)
# HMAC signing is ENABLED by default for secure inter-service communication
# Generate secret: openssl rand -hex 32
ML_SERVICE_HMAC_ENABLED=true
ML_SERVICE_HMAC_SECRET=CHANGE_ME_GENERATE_64_CHAR_HEX_ML_HMAC

# Log level for ML service
ML_LOG_LEVEL=info

# Circuit breaker (disable for internal Docker network)
ML_CIRCUIT_BREAKER_ENABLED=false

# -----------------------------------------------------------------------------
# 5.2 Uvicorn Workers
# -----------------------------------------------------------------------------
ML_UVICORN_WORKERS=4
UVICORN_WORKERS=4
UVICORN_TIMEOUT_KEEP_ALIVE=65
UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN=30
UVICORN_LIMIT_MAX_REQUESTS=50000
UVICORN_ACCESS_LOG=true

# CORS (ML Service)
CORS_ORIGINS=https://your-domain.example.com

# -----------------------------------------------------------------------------
# 5.3 Model Storage
# -----------------------------------------------------------------------------
MODEL_STORAGE_PATH=/app/models
ML_STORAGE_PATH=/data/ml-storage
MODEL_CACHE_SIZE=10

# SSOT Algorithm Configuration Path (Optional - rarely needed)
# Algorithm JSON files are automatically located in Docker images at /shared/algorithms/core
# Only override for custom deployments where algorithms are stored elsewhere
# SSOT_ALGORITHMS_PATH=/custom/path/to/algorithms/core
MAX_MODELS=50

# Model signing key for integrity verification
# Generate: openssl rand -hex 32
MODEL_SIGNING_KEY=CHANGE_ME_GENERATE_64_CHAR_HEX

# Service-to-service authentication key (Express backend → ML Service)
# Enables rate limit bypass for internal calls in multi-server deployments
# Generate: openssl rand -base64 32 | tr -d '\n/+='
INTERNAL_SERVICE_KEY=CHANGE_ME_GENERATE_INTERNAL_SERVICE_KEY

# -----------------------------------------------------------------------------
# 5.4 Rate Limiting (ML Service)
# -----------------------------------------------------------------------------
RATE_LIMIT_ENABLED=true
ML_RATE_LIMIT_ENABLED=true
MAX_PREDICTIONS_PER_DAY=10000
MAX_TRAINING_JOBS_PER_MONTH=100
MAX_BATCH_SIZE=1000

# -----------------------------------------------------------------------------
# 5.5 Celery Task Queue
# Redis DB Allocation:
#   DB 0: Backend (caching, sessions)
#   DB 1: Superset (caching)
#   DB 2: ML Service (caching)
#   DB 3: Celery (task queue broker and results)
# -----------------------------------------------------------------------------
CELERY_BROKER_URL=redis://redis:6379/3
CELERY_RESULT_BACKEND=redis://redis:6379/3
CELERY_TASK_TIME_LIMIT=7200
CELERY_TASK_SOFT_TIME_LIMIT=6900

# Celery Worker Concurrency
CELERY_TRAINING_CONCURRENCY=4
CELERY_PREDICTION_CONCURRENCY=4
CELERY_MONITORING_CONCURRENCY=2

# -----------------------------------------------------------------------------
# 5.6 Training Timeouts
# -----------------------------------------------------------------------------
TRAINING_TIMEOUT_SECONDS=14400
TRAINING_SOFT_TIMEOUT_SECONDS=14100
TUNING_TIMEOUT_SECONDS=14400
BATCH_PREDICTION_TIMEOUT_SECONDS=3600

# -----------------------------------------------------------------------------
# 5.7 Algorithm Configuration
# -----------------------------------------------------------------------------
ENABLE_CONFIGURABLE_ALGORITHMS=false
ENABLE_EXTENDED_ALGORITHMS=true
ENABLE_ADVANCED_ALGORITHMS=true
LAZY_LOAD_HEAVY_DEPS=true
GPU_REQUIRED_FOR_ADVANCED=true
GPU_MINIMUM_MEMORY_GB=4.0

# =============================================================================
# SECTION 6: SUPERSET CONFIGURATION
# =============================================================================

# -----------------------------------------------------------------------------
# 6.1 Superset Admin
# -----------------------------------------------------------------------------
SUPERSET_SECRET_KEY=CHANGE_ME_GENERATE_SECURE_64_CHAR_SECRET
SUPERSET_ADMIN_USERNAME=admin
SUPERSET_ADMIN_EMAIL=admin@example.com
# Generate password: openssl rand -base64 16 | tr -d '\n/+='
SUPERSET_ADMIN_PASSWORD=CHANGE_ME_ADMIN_PASSWORD

# -----------------------------------------------------------------------------
# 6.2 Superset Performance
# -----------------------------------------------------------------------------
SUPERSET_WORKERS=4
SUPERSET_WEBSERVER_TIMEOUT=300
SUPERSET_ENABLE_SYNC=true
SUPERSET_ROW_LIMIT=50000

# Superset feature flags
SUPERSET_ENABLE_PROXY_FIX=true

# Superset URLs (internal Docker network)
SUPERSET_URL=http://superset:8088
SUPERSET_API_URL=http://superset:8088
PLUGINS_DEV_PATH=/app/packages/pluginsdev
# Plugin Storage - persistent volume for uploaded plugin packages
PLUGIN_STORAGE_PATH=/app/plugins
SUPERSET_WEBSERVER_BASEPATH=/insights

# Platform Database for ML Analytics Dashboards
# Note: PLATFORM_DATABASE_URL is constructed by docker-compose from:
#   POSTGRES_USER, POSTGRES_PASSWORD, PLATFORM_DB
# This allows Superset to access ml_predictions, ml_models tables for analytics
# No manual configuration required - docker-compose handles the substitution

# =============================================================================
# SECTION 7: NODE BACKEND -> ML SERVICE COMMUNICATION
# =============================================================================

# Backend timeout when calling ML service
NODE_BACKEND_URL=http://backend:3000
NODE_BACKEND_TIMEOUT_SECONDS=900

# =============================================================================
# SECTION 8: JUPYTER NOTEBOOK SERVER (Optional)
# =============================================================================
# Run with: docker compose -f docker-compose.jupyter.yml up -d

# Jupyter Docker image (pin version for reproducibility)
JUPYTER_IMAGE=jupyter/scipy-notebook:2024-01-15

JUPYTER_SERVER_URL=http://jupyter:8888
# Generate: openssl rand -hex 32
JUPYTER_TOKEN=CHANGE_ME_JUPYTER_TOKEN
JUPYTER_TIMEOUT_SECONDS=3600
JUPYTER_KERNEL_NAME=python3
JUPYTER_WS_TIMEOUT_SECONDS=300
JUPYTER_MAX_KERNELS_PER_TENANT=10
JUPYTER_KERNEL_IDLE_TIMEOUT_MINUTES=30

# Deployment mode: "single" (shared server) or "jupyterhub" (enterprise)
JUPYTER_DEPLOYMENT_MODE=single

# Notebook storage
NOTEBOOK_STORAGE_BACKEND=local
NOTEBOOK_STORAGE_PATH=/data/notebooks
MAX_NOTEBOOK_SIZE_MB=50
NOTEBOOK_EXECUTION_TIMEOUT_SECONDS=7200

# =============================================================================
# SECTION 9: ENTERPRISE AUTHENTICATION (Optional)
# =============================================================================

# -----------------------------------------------------------------------------
# 9.1 LDAP/Active Directory
# -----------------------------------------------------------------------------
LDAP_ENABLED=false
LDAP_URL=ldap://ldap.example.com:389
LDAP_BIND_DN=cn=admin,dc=example,dc=com
LDAP_BIND_PASSWORD=
LDAP_SEARCH_BASE=ou=users,dc=example,dc=com
LDAP_SEARCH_FILTER=(uid={{username}})
LDAP_USERNAME_ATTRIBUTE=uid
LDAP_EMAIL_ATTRIBUTE=mail
LDAP_DISPLAY_NAME_ATTRIBUTE=displayName
LDAP_GROUP_SEARCH_BASE=ou=groups,dc=example,dc=com
LDAP_GROUP_SEARCH_FILTER=(member={{dn}})
LDAP_DEFAULT_ROLE=user
LDAP_TIMEOUT=5000
LDAP_CONNECT_TIMEOUT=10000

# -----------------------------------------------------------------------------
# 9.2 SAML 2.0 SSO
# -----------------------------------------------------------------------------
SAML_ENABLED=false
SAML_SP_ENTITY_ID=https://your-domain.example.com/saml/metadata
SAML_SP_ACS_URL=https://your-domain.example.com/saml/acs
SAML_SP_SLO_URL=https://your-domain.example.com/saml/slo
SAML_IDP_ENTITY_ID=
SAML_IDP_SSO_URL=
SAML_IDP_SLO_URL=
SAML_IDP_CERTIFICATE=
SAML_FORCE_AUTHN=false
SAML_ALLOW_UNENCRYPTED=false
SAML_SIGN_REQUESTS=false
SAML_WANT_ASSERTIONS_SIGNED=true
SAML_DEFAULT_ROLE=user

# =============================================================================
# SECTION 10: EMAIL SERVICE (Optional)
# =============================================================================

SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_SECURE=false
SMTP_USER=
SMTP_PASS=
SMTP_FROM_NAME="Pravaha Platform"
SMTP_FROM_ADDRESS=noreply@example.com
ORGANIZATION_NAME="Your Organization Name"

# =============================================================================
# SECTION 11: DATA RETENTION & CLEANUP
# =============================================================================

DATA_RETENTION_ENABLED=true
DATA_RETENTION_INTERVAL_HOURS=24
RETENTION_FAILED_EXECUTIONS_ENABLED=true
RETENTION_FAILED_EXECUTIONS_DAYS=30
RETENTION_SUCCESSFUL_EXECUTIONS_ENABLED=true
RETENTION_SUCCESSFUL_EXECUTIONS_DAYS=90
RETENTION_LOGS_ENABLED=true
RETENTION_LOGS_DAYS=60

# Session Cleanup
SESSION_RETENTION_DAYS=30
SESSION_CLEANUP_CRON="0 2 * * *"

# =============================================================================
# SECTION 12: WORKER SCALING (Optional - Advanced)
# =============================================================================

SCALING_MIN_WORKERS=2
SCALING_MAX_WORKERS=20
SCALING_TARGET_QUEUE_DEPTH=50
SCALING_UP_THRESHOLD=0.8
SCALING_DOWN_THRESHOLD=0.3
SCALING_UP_COOLDOWN=60000
SCALING_DOWN_COOLDOWN=300000
SCALING_HEALTH_CHECK_INTERVAL=30000
SCALING_WORKER_TIMEOUT=300000
SCALING_MAX_ERROR_RATE=10
SCALING_LOAD_BALANCING_STRATEGY=adaptive

# =============================================================================
# SECTION 13: NOTIFICATIONS (Optional)
# =============================================================================

SLACK_WEBHOOK_URL=
TEAMS_WEBHOOK_URL=
PAGERDUTY_ROUTING_KEY=

# =============================================================================
# SECTION 14: ENTERPRISE MONITORING & OBSERVABILITY (Optional)
# Comprehensive monitoring with Prometheus, Grafana, and Alertmanager
# =============================================================================
#
# LOGGING STACK (Loki + Promtail + Grafana):
#   docker compose -f docker-compose.yml -f docker-compose.logging.yml up -d
#
# METRICS STACK (Prometheus + Grafana + Alertmanager):
#   docker compose -f docker-compose.yml -f docker-compose.metrics.yml up -d
#
# FULL OBSERVABILITY (Both stacks):
#   docker compose -f docker-compose.yml -f docker-compose.logging.yml -f docker-compose.metrics.yml up -d
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# 14.1 Grafana Configuration (Shared by logging and metrics stacks)
# Generate password: openssl rand -base64 24 | tr -d '\n/+='
# -----------------------------------------------------------------------------
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=CHANGE_ME_GRAFANA_PASSWORD
# Generate: openssl rand -base64 32 | tr -d '\n/+='
GRAFANA_SECRET_KEY=CHANGE_ME_32_CHAR_SECRET_KEY

# Grafana security
GRAFANA_COOKIE_SECURE=false
GRAFANA_ANONYMOUS_ENABLED=false

# Grafana ports (logging stack uses 3001, metrics stack uses 3002)
GRAFANA_LOGS_PORT=3001
GRAFANA_METRICS_PORT=3002

# -----------------------------------------------------------------------------
# 14.2 Prometheus Configuration
# Metrics collection and storage
# -----------------------------------------------------------------------------
PROMETHEUS_PORT=9090
PROMETHEUS_RETENTION=15d
PROMETHEUS_RETENTION_SIZE=10GB

# -----------------------------------------------------------------------------
# 14.3 Alertmanager Configuration
# Alert routing and notification management
# -----------------------------------------------------------------------------
ALERTMANAGER_PORT=9093
ALERTMANAGER_EXTERNAL_URL=http://localhost:9093

# Alert notification emails (configure based on your team structure)
ALERT_EMAIL=ops@example.com
CRITICAL_ALERT_EMAIL=oncall@example.com
DBA_EMAIL=dba@example.com
ML_TEAM_EMAIL=ml-team@example.com
INFRA_EMAIL=infra@example.com

# Slack channels for alerts (optional, configure SLACK_WEBHOOK_URL in Section 13)
SLACK_CRITICAL_CHANNEL=#alerts-critical
SLACK_WARNING_CHANNEL=#alerts
SLACK_DBA_CHANNEL=#alerts-database
SLACK_ML_CHANNEL=#alerts-ml
SLACK_INFRA_CHANNEL=#alerts-infra

# =============================================================================
# SECTION 15: MULTI-TENANCY
# =============================================================================

DEFAULT_TENANT_ID=default

# =============================================================================
# SECTION 16: ELK STACK LOGGING (Optional)
# Enterprise-grade log aggregation with Elasticsearch, Logstash, Kibana
# Usage: docker compose -f docker-compose.yml -f docker-compose.elk.yml up -d
# Access: https://your-domain.com/elk/
# =============================================================================

# -----------------------------------------------------------------------------
# 16.1 Elasticsearch
# Generate password: openssl rand -base64 24 | tr -d '\n/+='
# -----------------------------------------------------------------------------
ELASTICSEARCH_USERNAME=elastic
ELASTIC_PASSWORD=CHANGE_ME_ELASTIC_PASSWORD
ELASTIC_SECURITY_ENABLED=true
ELASTIC_HEAP_SIZE=2g
ELASTIC_MEMORY_LIMIT=4G

# -----------------------------------------------------------------------------
# 16.2 Logstash
# -----------------------------------------------------------------------------
LOGSTASH_HEAP_SIZE=1g
LOGSTASH_MEMORY_LIMIT=2G

# -----------------------------------------------------------------------------
# 16.3 Kibana
# Generate encryption keys: openssl rand -base64 32 | tr -d '\n/+='
# Note: All three keys should be at least 32 characters
# -----------------------------------------------------------------------------
# Generate: openssl rand -base64 24 | tr -d '\n/+='
KIBANA_SYSTEM_PASSWORD=CHANGE_ME_KIBANA_PASSWORD
KIBANA_ENCRYPTION_KEY=CHANGE_ME_32_OR_MORE_CHARACTERS_KEY_ENCRYPTION
KIBANA_REPORTING_KEY=CHANGE_ME_32_OR_MORE_CHARACTERS_KEY_REPORTING
KIBANA_SECURITY_KEY=CHANGE_ME_32_OR_MORE_CHARACTERS_KEY_SECURITY

# =============================================================================
# SECTION 17: SUPER ADMIN (Platform Administration)
# =============================================================================
# Super Admin has elevated privileges for platform-wide administration
# Generate: openssl rand -base64 48 | tr -d '\n/+='
# -----------------------------------------------------------------------------
SUPER_ADMIN_EMAIL=superadmin@platform.local
# Generate password: openssl rand -base64 16 | tr -d '\n/+='
SUPER_ADMIN_DEFAULT_PASSWORD=CHANGE_ME_SUPER_ADMIN_PASSWORD
SUPER_ADMIN_JWT_SECRET=CHANGE_ME_GENERATE_SUPER_ADMIN_JWT_SECRET
SUPER_ADMIN_TOKEN_TTL=1h
